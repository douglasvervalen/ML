{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c490d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Download dos dados\n",
    "# transforms.ToTensor() -> Transforma imagem em matriz\n",
    "train_data = datasets.MNIST(\"\", download=True, train=True, transform=transforms.ToTensor()) \n",
    "test_data = datasets.MNIST(\"\", download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcec1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregamento dos dados\n",
    "X_train = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "X_test = DataLoader(test_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d6ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "class Produto():\n",
    "    def __init__(self):\n",
    "        self.nome = 'Camiseta'\n",
    "        self.preco = 30\n",
    "    def Desconto(self, x):\n",
    "        self.preco = self.preco - (self.preco * (x/100))\n",
    "        print(self.preco)\n",
    "        \n",
    "produto1 = Produto()\n",
    "produto1.Desconto(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f55542dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Rede(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    #[0.3, -1.4] -> [0.85, 0,15] -> [1, 0]\n",
    "    \n",
    "model = Rede()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "776d63d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as op\n",
    "optimizer = op.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(3):\n",
    "    for data in X_train:\n",
    "        X, y = data\n",
    "        Y = model(X.view(-1,784))\n",
    "        #otimizacao\n",
    "        model.zero_grad()\n",
    "        loss = F.nll_loss(Y, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47f4dddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0077,  0.0101, -0.0023,  ...,  0.0295, -0.0097,  0.0232],\n",
       "        [ 0.0084,  0.0243, -0.0326,  ..., -0.0242, -0.0010, -0.0355],\n",
       "        [ 0.0148,  0.0087,  0.0183,  ..., -0.0145, -0.0080,  0.0038],\n",
       "        ...,\n",
       "        [-0.0312, -0.0063,  0.0145,  ..., -0.0292,  0.0287, -0.0356],\n",
       "        [ 0.0347,  0.0043, -0.0256,  ..., -0.0078, -0.0121, -0.0079],\n",
       "        [-0.0340,  0.0001,  0.0108,  ..., -0.0101, -0.0202, -0.0340]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pesos da camada fc1\n",
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78b9d19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "correct = 0\n",
    "total = 0\n",
    "for epoch in range(3):\n",
    "    for data in X_test:\n",
    "        X, y = data\n",
    "        Y = model(X.view(-1,784))\n",
    "        for index, i in enumerate(Y):\n",
    "            if torch.argmax(i) == y[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(round((correct/total)*100,3))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f310c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(\"Drawing6.png\")\n",
    "image = transforms.ToTensor()(img)\n",
    "\n",
    "plt.imshow(image[0].view(28,28))\n",
    "print(torch.argmax(model(image[0].view(-1,784))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
